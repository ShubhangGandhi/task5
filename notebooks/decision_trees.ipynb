# %% [markdown]
# # Task 5: Decision Trees & Random Forests
# ## Heart Disease Prediction

# %% [markdown]
# ### 1. Import Libraries
# %%
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import (accuracy_score, confusion_matrix, 
                            classification_report, roc_auc_score)
from IPython.display import Image
import graphviz

# %% [markdown]
# ### 2. Load and Explore Data
# %%
# Load dataset
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"
cols = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 
        'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']
df = pd.read_csv(url, names=cols, na_values='?')

# Convert target to binary (0: No disease, 1: Disease)
df['target'] = df['target'].apply(lambda x: 1 if x > 0 else 0)

# Handle missing values
df.fillna(df.median(), inplace=True)

# Display info
print("Dataset shape:", df.shape)
display(df.head())

# %% [markdown]
# ### 3. Preprocessing
# %%
# Split features and target
X = df.drop('target', axis=1)
y = df['target']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# %% [markdown]
# ### 4. Decision Tree Classifier
# %%
# Base model (prone to overfitting)
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)

# Evaluate
y_pred = dt.predict(X_test)
print("Base Decision Tree Accuracy:", accuracy_score(y_test, y_pred))

# Visualize tree (requires Graphviz)
dot_data = export_graphviz(dt, out_file=None, 
                          feature_names=X.columns,
                          class_names=['Healthy', 'Disease'],
                          filled=True, rounded=True)
graph = graphviz.Source(dot_data)
graph.render("images/decision_tree", format='png')
Image(filename='images/decision_tree.png')

# %% [markdown]
# ### 5. Controlling Overfitting
# %%
# Pruned model
dt_pruned = DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, random_state=42)
dt_pruned.fit(X_train, y_train)

# Compare accuracy
print("Pruned Tree Accuracy:", accuracy_score(y_test, dt_pruned.predict(X_test)))

# Feature Importance
plt.figure(figsize=(10,6))
pd.Series(dt_pruned.feature_importances_, index=X.columns).sort_values().plot(kind='barh')
plt.title('Feature Importance (Decision Tree)')
plt.savefig('images/feature_importance.png')
plt.show()

# %% [markdown]
# ### 6. Random Forest Classifier
# %%
# Initialize and train
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Evaluate
y_pred_rf = rf.predict(X_test)
print("\nRandom Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print("ROC-AUC Score:", roc_auc_score(y_test, rf.predict_proba(X_test)[:,1]))

# Cross-validation
cv_scores = cross_val_score(rf, X, y, cv=5)
plt.figure(figsize=(8,4))
plt.bar(range(1,6), cv_scores)
plt.ylim(0.7, 1.0)
plt.title('5-Fold Cross-Validation Scores')
plt.savefig('images/cv_scores.png')
plt.show()

# %% [markdown]
# ### 7. Model Comparison
# %%
print("\nClassification Report (Random Forest):")
print(classification_report(y_test, y_pred_rf))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Healthy', 'Disease'],
            yticklabels=['Healthy', 'Disease'])
plt.title('Random Forest Confusion Matrix')
plt.show()
